{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n",
      "tensor([0.2400, 0.2600, 0.2400, 0.2600])\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/Users/jmmoon/Documents/GitHub/LDPUts')\n",
    "import gc\n",
    "from discretizer import discretizer\n",
    "from client import client\n",
    "import torch\n",
    "from server import server_ell2, server_multinomial_genrr, server_multinomial_bitflip, server_multinomial_bitflip_old\n",
    "from data_generator import data_generator\n",
    "from discretizer import discretizer\n",
    "import time\n",
    "import numpy as np\n",
    "from scipy.stats import chi2\n",
    "from utils import chi_sq_dist\n",
    "\n",
    "\n",
    "device = torch.device(\"mps\")\n",
    "print(device)\n",
    "\n",
    "sample_size = 10000\n",
    "privacy_level = 2.0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "n_test = 300\n",
    "n_permutation = 2\n",
    "significance_level = 0.05\n",
    "alphabet_size = 4\n",
    "\n",
    "p1 = torch.ones(alphabet_size).div(alphabet_size)\n",
    "\n",
    "bump_size = 0.01\n",
    "p2 = p1.add(\n",
    "    torch.remainder(\n",
    "    torch.tensor(range(alphabet_size)),\n",
    "    2\n",
    "    ).add(-1/2).mul(2).mul(bump_size)\n",
    ")\n",
    "print(p2)\n",
    "\n",
    "\n",
    "alphabet_size = 4\n",
    "    \n",
    "data_gen = data_generator()\n",
    "LDPclient = client()\n",
    "\n",
    "\n",
    "server_bitflip = server_multinomial_bitflip(privacy_level)\n",
    "server_bitflip_old = server_multinomial_bitflip_old(privacy_level)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "grand_mean = torch.mean(torch.vstack((server_bitflip.data_y, server_bitflip.data_z)),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2356, -0.0122, -0.0137, -0.0122],\n",
       "        [-0.0122,  0.2362, -0.0108, -0.0148],\n",
       "        [-0.0137, -0.0108,  0.2365, -0.0115],\n",
       "        [-0.0122, -0.0148, -0.0115,  0.2359]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cov(torch.vstack((server_bitflip.data_y, server_bitflip.data_z)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2356, -0.0122, -0.0137, -0.0122],\n",
       "        [-0.0122,  0.2361, -0.0108, -0.0148],\n",
       "        [-0.0137, -0.0108,  0.2365, -0.0114],\n",
       "        [-0.0122, -0.0148, -0.0114,  0.2359]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.cov(server_bitflip.data_y.T).mul(10000-1) + torch.cov(server_bitflip.data_z.T).mul(10000-1)).div(20000-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov = server_bitflip.data_y.sub(grand_mean).T.matmul(server_bitflip.data_y.sub(grand_mean)).add(\n",
    "    server_bitflip.data_z.sub(grand_mean).T.matmul(server_bitflip.data_z.sub(grand_mean))\n",
    ").div(20000-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.9236, 1.9274, 1.9158, 1.9301])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linalg.inv(cov).matmul(grand_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1,2,3,4][:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  def _get_scaling_matrix(self):\n",
    "        mat_proj = self.get_proj_orth_one_space()\n",
    "        if self.cuda_device.type== \"cpu\":\n",
    "            prec_mat_est =  torch.tensor(numpy.linalg.inv(torch.cov(self.data.T).numpy()))\n",
    "        else:\n",
    "            prec_mat_est =  torch.linalg.inv(torch.cov(self.data.T))\n",
    "        return(\n",
    "            mat_proj.matmul(prec_mat_est.to(self.cuda_device)).matmul(mat_proj)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "og\n",
      "tensor([[-0.0039],\n",
      "        [-0.0086],\n",
      "        [ 0.0061],\n",
      "        [-0.0106]])\n",
      "tensor([[0.2050]])\n",
      "perm\n",
      "og\n",
      "tensor([[-0.0039],\n",
      "        [-0.0086],\n",
      "        [ 0.0061],\n",
      "        [-0.0106]])\n",
      "tensor([[3.3803]])\n",
      "perm\n",
      "pval: 0.0 -- 0.9767746550754082(perm), 1th test, time elapsed 0.2374269962310791\n",
      "pval old: 0.0 -- 0.336618316737033(perm old), 1th test, time elapsed 0.2374269962310791\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "p_value_array = np.zeros([n_test, 2])\n",
    "p_value_array_old = np.zeros([n_test, 2])\n",
    "\n",
    "\n",
    "for i in range(1):\n",
    "    t_start_i = time.time()\n",
    "    torch.manual_seed(i)\n",
    "    data_priv_y = LDPclient.release_bitflip(\n",
    "            data_gen.generate_multinomial_data(p1, sample_size),\n",
    "            alphabet_size,\n",
    "            privacy_level\n",
    "            )\n",
    "    data_priv_z = LDPclient.release_bitflip(\n",
    "            data_gen.generate_multinomial_data(p2, sample_size),\n",
    "            alphabet_size,\n",
    "            privacy_level\n",
    "    )\n",
    "    server_bitflip_old.load_private_data_multinomial_y(data_priv_y, alphabet_size)\n",
    "    server_bitflip_old.load_private_data_multinomial_z(data_priv_z, alphabet_size)\n",
    "\n",
    "    server_bitflip.load_private_data_multinomial_y(data_priv_y, alphabet_size)\n",
    "    server_bitflip.load_private_data_multinomial_z(data_priv_z, alphabet_size)\n",
    "\n",
    "    print(\"og\")\n",
    "    p_value_array[i,1] = server_bitflip.release_p_value()\n",
    "    print(\"perm\")\n",
    "    #p_value_array[i,0] = server_bitflip.release_p_value_permutation(n_permutation)\n",
    "    \n",
    "    print(\"og\")\n",
    "    p_value_array_old[i,1] = server_bitflip_old.release_p_value()\n",
    "    print(\"perm\")\n",
    "    #p_value_array_old[i,0] = server_bitflip_old.release_p_value_permutation(n_permutation)\n",
    "    \n",
    "    \n",
    "    t_end_i = time.time() - t_start_i\n",
    "    print(f\"pval: {p_value_array[i,0]} -- {p_value_array[i,1]}(perm), {i+1}th test, time elapsed {t_end_i}\")\n",
    "    print(f\"pval old: {p_value_array_old[i,0]} -- {p_value_array_old[i,1]}(perm old), {i+1}th test, time elapsed {t_end_i}\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "server_bitflip_old.alphabet_size"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
