{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n",
      "tensor([0.2400, 0.2600, 0.2400, 0.2600])\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/Users/jmmoon/Documents/GitHub/LDPUts')\n",
    "import gc\n",
    "from discretizer import discretizer\n",
    "from client import client\n",
    "import torch\n",
    "from server import server_ell2, server_multinomial_genrr, server_multinomial_bitflip, server_multinomial_bitflip_old\n",
    "from data_generator import data_generator\n",
    "from discretizer import discretizer\n",
    "import time\n",
    "import numpy as np\n",
    "from scipy.stats import chi2\n",
    "from utils import chi_sq_dist\n",
    "\n",
    "\n",
    "device = torch.device(\"mps\")\n",
    "print(device)\n",
    "\n",
    "sample_size = 10000\n",
    "privacy_level = 2.0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "n_test = 300\n",
    "n_permutation = 9999\n",
    "significance_level = 0.05\n",
    "alphabet_size = 4\n",
    "\n",
    "p1 = torch.ones(alphabet_size).div(alphabet_size)\n",
    "\n",
    "bump_size = 0.01\n",
    "p2 = p1.add(\n",
    "    torch.remainder(\n",
    "    torch.tensor(range(alphabet_size)),\n",
    "    2\n",
    "    ).add(-1/2).mul(2).mul(bump_size)\n",
    ")\n",
    "print(p2)\n",
    "\n",
    "\n",
    "alphabet_size = 4\n",
    "    \n",
    "data_gen = data_generator()\n",
    "LDPclient = client()\n",
    "\n",
    "\n",
    "server_bitflip = server_multinomial_bitflip(privacy_level)\n",
    "server_bitflip_old = server_multinomial_bitflip_old(privacy_level)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "grand_mean = torch.mean(torch.vstack((server_bitflip.data_y, server_bitflip.data_z)),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2356, -0.0122, -0.0137, -0.0122],\n",
       "        [-0.0122,  0.2362, -0.0108, -0.0148],\n",
       "        [-0.0137, -0.0108,  0.2365, -0.0115],\n",
       "        [-0.0122, -0.0148, -0.0115,  0.2359]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cov(torch.vstack((server_bitflip.data_y, server_bitflip.data_z)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2356, -0.0122, -0.0137, -0.0122],\n",
       "        [-0.0122,  0.2361, -0.0108, -0.0148],\n",
       "        [-0.0137, -0.0108,  0.2365, -0.0114],\n",
       "        [-0.0122, -0.0148, -0.0114,  0.2359]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(torch.cov(server_bitflip.data_y.T).mul(10000-1) + torch.cov(server_bitflip.data_z.T).mul(10000-1)).div(20000-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov = server_bitflip.data_y.sub(grand_mean).T.matmul(server_bitflip.data_y.sub(grand_mean)).add(\n",
    "    server_bitflip.data_z.sub(grand_mean).T.matmul(server_bitflip.data_z.sub(grand_mean))\n",
    ").div(20000-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.9236, 1.9274, 1.9158, 1.9301])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linalg.inv(cov).matmul(grand_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "  def _get_scaling_matrix(self):\n",
    "        mat_proj = self.get_proj_orth_one_space()\n",
    "        if self.cuda_device.type== \"cpu\":\n",
    "            prec_mat_est =  torch.tensor(numpy.linalg.inv(torch.cov(self.data.T).numpy()))\n",
    "        else:\n",
    "            prec_mat_est =  torch.linalg.inv(torch.cov(self.data.T))\n",
    "        return(\n",
    "            mat_proj.matmul(prec_mat_est.to(self.cuda_device)).matmul(mat_proj)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "og\n",
      "tensor(3.3803)\n",
      "tensor(3.)\n",
      "tensor(3.3803)\n",
      "perm\n",
      "tensor(3.3803)\n",
      "og\n",
      "tensor([[3.3803]])\n",
      "tensor(3.)\n",
      "perm\n",
      "tensor([[3.3803]])\n",
      "pval: 0.33661818504333496 -- 0.29750001430511475(perm), 1th test, time elapsed 1.1077489852905273\n",
      "pval old: 0.33661818504333496 -- 0.30250000953674316(perm old), 1th test, time elapsed 1.1077489852905273\n",
      "\n",
      "og\n",
      "tensor(6.7960)\n",
      "tensor(3.)\n",
      "tensor(6.7960)\n",
      "perm\n",
      "tensor(6.7960)\n",
      "og\n",
      "tensor([[6.7960]])\n",
      "tensor(3.)\n",
      "perm\n",
      "tensor([[6.7960]])\n",
      "pval: 0.07869058847427368 -- 0.07999999821186066(perm), 2th test, time elapsed 1.0616068840026855\n",
      "pval old: 0.0786905288696289 -- 0.08749999850988388(perm old), 2th test, time elapsed 1.0616068840026855\n",
      "\n",
      "og\n",
      "tensor(14.8683)\n",
      "tensor(3.)\n",
      "tensor(14.8683)\n",
      "perm\n",
      "tensor(14.8683)\n",
      "og\n",
      "tensor([[14.8683]])\n",
      "tensor(3.)\n",
      "perm\n",
      "tensor([[14.8683]])\n",
      "pval: 0.0019327402114868164 -- 0.007499999832361937(perm), 3th test, time elapsed 1.0566682815551758\n",
      "pval old: 0.0019327402114868164 -- 0.0024999999441206455(perm old), 3th test, time elapsed 1.0566682815551758\n",
      "\n",
      "og\n",
      "tensor(6.7017)\n",
      "tensor(3.)\n",
      "tensor(6.7017)\n",
      "perm\n",
      "tensor(6.7017)\n",
      "og\n",
      "tensor([[6.7017]])\n",
      "tensor(3.)\n",
      "perm\n",
      "tensor([[6.7017]])\n",
      "pval: 0.08203768730163574 -- 0.09749999642372131(perm), 4th test, time elapsed 1.0562801361083984\n",
      "pval old: 0.08203768730163574 -- 0.07000000029802322(perm old), 4th test, time elapsed 1.0562801361083984\n",
      "\n",
      "og\n",
      "tensor(6.5581)\n",
      "tensor(3.)\n",
      "tensor(6.5581)\n",
      "perm\n",
      "tensor(6.5581)\n",
      "og\n",
      "tensor([[6.5581]])\n",
      "tensor(3.)\n",
      "perm\n",
      "tensor([[6.5581]])\n",
      "pval: 0.0873987078666687 -- 0.10499999672174454(perm), 5th test, time elapsed 1.0606610774993896\n",
      "pval old: 0.0873987078666687 -- 0.09749999642372131(perm old), 5th test, time elapsed 1.0606610774993896\n",
      "\n",
      "og\n",
      "tensor(3.7196)\n",
      "tensor(3.)\n",
      "tensor(3.7196)\n",
      "perm\n",
      "tensor(3.7196)\n",
      "og\n",
      "tensor([[3.7196]])\n",
      "tensor(3.)\n",
      "perm\n",
      "tensor([[3.7196]])\n",
      "pval: 0.2933768033981323 -- 0.3174999952316284(perm), 6th test, time elapsed 1.0657219886779785\n",
      "pval old: 0.2933768033981323 -- 0.2750000059604645(perm old), 6th test, time elapsed 1.0657219886779785\n",
      "\n",
      "og\n",
      "tensor(3.5872)\n",
      "tensor(3.)\n",
      "tensor(3.5872)\n",
      "perm\n",
      "tensor(3.5872)\n",
      "og\n",
      "tensor([[3.5872]])\n",
      "tensor(3.)\n",
      "perm\n",
      "tensor([[3.5872]])\n",
      "pval: 0.30963170528411865 -- 0.29499998688697815(perm), 7th test, time elapsed 1.0656278133392334\n",
      "pval old: 0.3096316456794739 -- 0.33500000834465027(perm old), 7th test, time elapsed 1.0656278133392334\n",
      "\n",
      "og\n",
      "tensor(13.3981)\n",
      "tensor(3.)\n",
      "tensor(13.3981)\n",
      "perm\n",
      "tensor(13.3981)\n",
      "og\n",
      "tensor([[13.3981]])\n",
      "tensor(3.)\n",
      "perm\n",
      "tensor([[13.3981]])\n",
      "pval: 0.0038501620292663574 -- 0.004999999888241291(perm), 8th test, time elapsed 1.0649948120117188\n",
      "pval old: 0.0038501620292663574 -- 0.0024999999441206455(perm old), 8th test, time elapsed 1.0649948120117188\n",
      "\n",
      "og\n",
      "tensor(5.0548)\n",
      "tensor(3.)\n",
      "tensor(5.0548)\n",
      "perm\n",
      "tensor(5.0548)\n",
      "og\n",
      "tensor([[5.0548]])\n",
      "tensor(3.)\n",
      "perm\n",
      "tensor([[5.0548]])\n",
      "pval: 0.16782855987548828 -- 0.13249999284744263(perm), 9th test, time elapsed 1.07669997215271\n",
      "pval old: 0.1678285002708435 -- 0.17749999463558197(perm old), 9th test, time elapsed 1.07669997215271\n",
      "\n",
      "og\n",
      "tensor(5.2992)\n",
      "tensor(3.)\n",
      "tensor(5.2992)\n",
      "perm\n",
      "tensor(5.2992)\n",
      "og\n",
      "tensor([[5.2992]])\n",
      "tensor(3.)\n",
      "perm\n",
      "tensor([[5.2992]])\n",
      "pval: 0.1511513590812683 -- 0.1525000035762787(perm), 10th test, time elapsed 1.073246955871582\n",
      "pval old: 0.1511513590812683 -- 0.1574999988079071(perm old), 10th test, time elapsed 1.073246955871582\n",
      "\n",
      "og\n",
      "tensor(4.1908)\n",
      "tensor(3.)\n",
      "tensor(4.1908)\n",
      "perm\n",
      "tensor(4.1908)\n",
      "og\n",
      "tensor([[4.1908]])\n",
      "tensor(3.)\n",
      "perm\n",
      "tensor([[4.1908]])\n",
      "pval: 0.24158340692520142 -- 0.26499998569488525(perm), 11th test, time elapsed 1.095168113708496\n",
      "pval old: 0.24158340692520142 -- 0.2199999988079071(perm old), 11th test, time elapsed 1.095168113708496\n",
      "\n",
      "og\n",
      "tensor(4.5067)\n",
      "tensor(3.)\n",
      "tensor(4.5067)\n",
      "perm\n",
      "tensor(4.5067)\n",
      "og\n",
      "tensor([[4.5067]])\n",
      "tensor(3.)\n",
      "perm\n",
      "tensor([[4.5067]])\n",
      "pval: 0.2116904854774475 -- 0.20000000298023224(perm), 12th test, time elapsed 1.098299264907837\n",
      "pval old: 0.2116904854774475 -- 0.2475000023841858(perm old), 12th test, time elapsed 1.098299264907837\n",
      "\n",
      "og\n",
      "tensor(1.4900)\n",
      "tensor(3.)\n",
      "tensor(1.4900)\n",
      "perm\n",
      "tensor(1.4900)\n",
      "og\n",
      "tensor([[1.4900]])\n",
      "tensor(3.)\n",
      "perm\n",
      "tensor([[1.4900]])\n",
      "pval: 0.6845780611038208 -- 0.699999988079071(perm), 13th test, time elapsed 1.0835199356079102\n",
      "pval old: 0.6845779418945312 -- 0.6800000071525574(perm old), 13th test, time elapsed 1.0835199356079102\n",
      "\n",
      "og\n",
      "tensor(1.5611)\n",
      "tensor(3.)\n",
      "tensor(1.5611)\n",
      "perm\n",
      "tensor(1.5611)\n",
      "og\n",
      "tensor([[1.5611]])\n",
      "tensor(3.)\n",
      "perm\n",
      "tensor([[1.5611]])\n",
      "pval: 0.6682366132736206 -- 0.6949999928474426(perm), 14th test, time elapsed 1.1056828498840332\n",
      "pval old: 0.6682366132736206 -- 0.6675000190734863(perm old), 14th test, time elapsed 1.1056828498840332\n",
      "\n",
      "og\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m server_bitflip\u001b[38;5;241m.\u001b[39mload_private_data_multinomial_z(data_priv_z, alphabet_size)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mog\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 25\u001b[0m p_value_array[i,\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mserver_bitflip\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrelease_p_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mperm\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     27\u001b[0m p_value_array[i,\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m server_bitflip\u001b[38;5;241m.\u001b[39mrelease_p_value_permutation(n_permutation)\n",
      "File \u001b[0;32m~/Documents/GitHub/LDPUts/server.py:185\u001b[0m, in \u001b[0;36mrelease_p_value\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrand_mean \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_grand_mean()\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcov_est \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(\n\u001b[1;32m    171\u001b[0m         torch\u001b[38;5;241m.\u001b[39mtranspose( \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_y\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrand_mean),\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m ),\n\u001b[1;32m    172\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_y\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrand_mean)\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    184\u001b[0m             )\n\u001b[0;32m--> 185\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrelease_p_value\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    186\u001b[0m     test_stat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_original_statistic()\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchisq_distribution\u001b[38;5;241m.\u001b[39mdf)\n",
      "File \u001b[0;32m~/Documents/GitHub/LDPUts/server.py:68\u001b[0m, in \u001b[0;36mget_original_statistic\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     64\u001b[0m         permuted_statistic_vec[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_statistic( torch\u001b[38;5;241m.\u001b[39mrandperm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_1 \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_2) )\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_p_value_proxy(permuted_statistic_vec, original_statistic))\n\u001b[0;32m---> 68\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_original_statistic\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     69\u001b[0m    original_statistic \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_statistic( torch\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_1 \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_2) )\n\u001b[1;32m     70\u001b[0m    \u001b[38;5;28mprint\u001b[39m(original_statistic)\n",
      "File \u001b[0;32m~/Documents/GitHub/LDPUts/server.py:197\u001b[0m, in \u001b[0;36m_get_statistic\u001b[0;34m(self, perm)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_statistic\u001b[39m(\u001b[38;5;28mself\u001b[39m, perm):\n\u001b[1;32m    195\u001b[0m     proj_mu_hat_diff \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmv(\n\u001b[1;32m    196\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_proj_orth_one_space(),\n\u001b[0;32m--> 197\u001b[0m         torch\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    198\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_mean_y(perm),\n\u001b[1;32m    199\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_mean_z(perm)\n\u001b[1;32m    200\u001b[0m         )\n\u001b[1;32m    201\u001b[0m     )\n\u001b[1;32m    203\u001b[0m     scaling_constant \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mreciprocal( torch\u001b[38;5;241m.\u001b[39madd( \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_1\u001b[38;5;241m.\u001b[39mreciprocal(), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_2\u001b[38;5;241m.\u001b[39mreciprocal() ) )\n\u001b[1;32m    205\u001b[0m     statistic \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdot(\n\u001b[1;32m    206\u001b[0m         proj_mu_hat_diff,\n\u001b[1;32m    207\u001b[0m         torch\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39msolve(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcov_est, proj_mu_hat_diff)\n\u001b[1;32m    208\u001b[0m     )\u001b[38;5;241m.\u001b[39mmul(scaling_constant)\n",
      "File \u001b[0;32m~/Documents/GitHub/LDPUts/server.py:106\u001b[0m, in \u001b[0;36mget_mean_y\u001b[0;34m(self, perm)\u001b[0m\n\u001b[1;32m    103\u001b[0m     _, _, perm_toZ_fromY, perm_toZ_fromZ \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39msplit_perm(perm, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_1)\n\u001b[1;32m    104\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_y[perm_toZ_fromY]\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcuda_device_z )\u001b[38;5;241m.\u001b[39madd( \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_z[perm_toZ_fromZ]\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m0\u001b[39m) ))\n\u001b[0;32m--> 106\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_mean_y\u001b[39m(\u001b[38;5;28mself\u001b[39m, perm):\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_sum_y(perm)\u001b[38;5;241m.\u001b[39mdiv(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_1)\n\u001b[1;32m    109\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_mean_z\u001b[39m(\u001b[38;5;28mself\u001b[39m, perm):\n",
      "File \u001b[0;32m~/Documents/GitHub/LDPUts/server.py:99\u001b[0m, in \u001b[0;36mget_sum_y\u001b[0;34m(self, perm)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_sum_y\u001b[39m(\u001b[38;5;28mself\u001b[39m, perm ):\n\u001b[0;32m---> 99\u001b[0m     perm_toY_fromY, perm_toY_fromZ, _, _ \u001b[38;5;241m=\u001b[39m utils\u001b[38;5;241m.\u001b[39msplit_perm(perm, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_1)\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_y[perm_toY_fromY]\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcuda_device_z )\u001b[38;5;241m.\u001b[39madd( \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_z[perm_toY_fromZ]\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m0\u001b[39m) ))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "p_value_array = np.zeros([n_test, 2])\n",
    "p_value_array_old = np.zeros([n_test, 2])\n",
    "\n",
    "\n",
    "for i in range(3):\n",
    "    t_start_i = time.time()\n",
    "    torch.manual_seed(i)\n",
    "    data_priv_y = LDPclient.release_bitflip(\n",
    "            data_gen.generate_multinomial_data(p1, sample_size),\n",
    "            alphabet_size,\n",
    "            privacy_level\n",
    "            )\n",
    "    data_priv_z = LDPclient.release_bitflip(\n",
    "            data_gen.generate_multinomial_data(p2, sample_size),\n",
    "            alphabet_size,\n",
    "            privacy_level\n",
    "    )\n",
    "    server_bitflip_old.load_private_data_multinomial_y(data_priv_y, alphabet_size)\n",
    "    server_bitflip_old.load_private_data_multinomial_z(data_priv_z, alphabet_size)\n",
    "\n",
    "    server_bitflip.load_private_data_multinomial_y(data_priv_y, alphabet_size)\n",
    "    server_bitflip.load_private_data_multinomial_z(data_priv_z, alphabet_size)\n",
    "\n",
    "    print(\"og\")\n",
    "    p_value_array[i,1] = server_bitflip.release_p_value()\n",
    "    print(\"perm\")\n",
    "    p_value_array[i,0] = server_bitflip.release_p_value_permutation(n_permutation)\n",
    "    \n",
    "    print(\"og\")\n",
    "    p_value_array_old[i,1] = server_bitflip_old.release_p_value()\n",
    "    print(\"perm\")\n",
    "    p_value_array_old[i,0] = server_bitflip_old.release_p_value_permutation(n_permutation)\n",
    "    \n",
    "    \n",
    "    t_end_i = time.time() - t_start_i\n",
    "    print(f\"pval: {p_value_array[i,1]} -- {p_value_array[i,0]}(perm), {i+1}th test, time elapsed {t_end_i}\")\n",
    "    print(f\"pval old: {p_value_array_old[i,1]} -- {p_value_array_old[i,0]}(perm old), {i+1}th test, time elapsed {t_end_i}\\n\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
