{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '/mnt/nas/users/mjm/LDPUts')\n",
    "\n",
    "from discretizer import discretizer\n",
    "from client import client\n",
    "import torch\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "import matplotlib.pyplot as plt\n",
    "from server import server_ell2, server_multinomial_genRR, server_multinomial_bitflip\n",
    "from data_generator import data_generator\n",
    "from discretizer import discretizer\n",
    "import time\n",
    "import numpy as np\n",
    "from scipy.stats import chi2\n",
    "from utils import chi_sq_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2400, 0.2600, 0.2400, 0.2600])\n"
     ]
    }
   ],
   "source": [
    "n_test = 100\n",
    "n_permutation = 99\n",
    "significance_level = 0.05\n",
    "alphabet_size = 4\n",
    "sample_size = 20000\n",
    "\n",
    "###################\n",
    "###################\n",
    "\n",
    "data_gen = data_generator(device)\n",
    "\n",
    "p1 = torch.ones(alphabet_size).div(alphabet_size)\n",
    "\n",
    "bump_size = 0.01\n",
    "p2 = p1.add(\n",
    "    torch.remainder(\n",
    "    torch.tensor(range(alphabet_size)),\n",
    "    2\n",
    "    ).add(-1/2).mul(2).mul(bump_size)\n",
    ")\n",
    "print(p2)\n",
    "p_value_array_priv_01 = np.zeros([n_test, 5])\n",
    "p_value_array_priv_05 = np.zeros([n_test, 5])\n",
    "p_value_array_priv_10 = np.zeros([n_test, 5])\n",
    "p_value_array_priv_20 = np.zeros([n_test, 5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## privacy level = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1th test\n",
      "2th test\n",
      "3th test\n",
      "4th test\n",
      "5th test\n",
      "6th test\n",
      "7th test\n",
      "8th test\n",
      "9th test\n",
      "10th test\n",
      "11th test\n",
      "12th test\n",
      "13th test\n",
      "14th test\n",
      "15th test\n",
      "16th test\n",
      "17th test\n",
      "18th test\n",
      "19th test\n",
      "20th test\n",
      "21th test\n",
      "22th test\n",
      "23th test\n",
      "24th test\n",
      "25th test\n",
      "26th test\n",
      "27th test\n",
      "28th test\n",
      "29th test\n",
      "30th test\n",
      "31th test\n",
      "32th test\n",
      "33th test\n",
      "34th test\n",
      "35th test\n",
      "36th test\n",
      "37th test\n",
      "38th test\n",
      "39th test\n",
      "40th test\n",
      "41th test\n",
      "42th test\n",
      "43th test\n",
      "44th test\n",
      "45th test\n",
      "46th test\n",
      "47th test\n",
      "48th test\n",
      "49th test\n",
      "50th test\n",
      "51th test\n",
      "52th test\n",
      "53th test\n",
      "54th test\n",
      "55th test\n",
      "56th test\n",
      "57th test\n",
      "58th test\n",
      "59th test\n",
      "60th test\n",
      "61th test\n",
      "62th test\n",
      "63th test\n",
      "64th test\n",
      "65th test\n",
      "66th test\n",
      "67th test\n",
      "68th test\n",
      "69th test\n",
      "70th test\n",
      "71th test\n",
      "72th test\n",
      "73th test\n",
      "74th test\n",
      "75th test\n",
      "76th test\n",
      "77th test\n",
      "78th test\n",
      "79th test\n",
      "80th test\n",
      "81th test\n",
      "82th test\n",
      "83th test\n",
      "84th test\n",
      "85th test\n",
      "86th test\n",
      "87th test\n",
      "88th test\n",
      "89th test\n",
      "90th test\n",
      "91th test\n",
      "92th test\n",
      "93th test\n",
      "94th test\n",
      "95th test\n",
      "96th test\n",
      "97th test\n",
      "98th test\n",
      "99th test\n",
      "100th test\n"
     ]
    }
   ],
   "source": [
    "p_value_array_priv_10_n_20000 = np.zeros([n_test, 6])\n",
    "\n",
    "privacy_level = 1.0\n",
    "LDPclient = client(device, privacy_level)\n",
    "\n",
    "server_elltwo = server_ell2(device, privacy_level)\n",
    "server_elltwo_disc = server_ell2(device, privacy_level)\n",
    "\n",
    "server_genrr = server_multinomial_genRR(device, privacy_level)\n",
    "server_bitflip = server_multinomial_bitflip(device, privacy_level)\n",
    "\n",
    "\n",
    "\n",
    "t = time.time()\n",
    "for i in range(n_test):\n",
    "    print(f\"{i+1}th test\")\n",
    "    torch.manual_seed(i)\n",
    "    data_y = data_gen.generate_multinomial_data(p1, sample_size)\n",
    "    data_z = data_gen.generate_multinomial_data(p2, sample_size)\n",
    "    LDPclient.load_data_multinomial(data_y, data_z, alphabet_size)\n",
    "    \n",
    "    data_lapu_y, data_lapu_z = LDPclient.release_LapU()\n",
    "    server_elltwo.load_private_data_multinomial(data_lapu_y, data_lapu_z, alphabet_size)\n",
    "    p_value_array_priv_10_n_20000[i,0] = server_elltwo.release_p_value_permutation(n_permutation)\n",
    "    \n",
    "    data_disclapu_y, data_disclapu_z = LDPclient.release_DiscLapU()\n",
    "    server_elltwo_disc.load_private_data_multinomial(data_disclapu_y, data_disclapu_z, alphabet_size)\n",
    "    p_value_array_priv_10_n_20000[i,1] = server_elltwo_disc.release_p_value_permutation(n_permutation)\n",
    "    \n",
    "    data_genrr_y, data_genrr_z = LDPclient.release_genRR()\n",
    "    server_genrr.load_private_data_multinomial(data_genrr_y, data_genrr_z, alphabet_size)\n",
    "    p_value_array_priv_10_n_20000[i,2] = server_genrr.release_p_value_permutation(n_permutation)\n",
    "    p_value_array_priv_10_n_20000[i,3] = server_genrr.release_p_value()\n",
    "    \n",
    "    data_bitflip_y, data_bitflip_z = LDPclient.release_bitFlip()\n",
    "    server_bitflip.load_private_data_multinomial(data_bitflip_y, data_bitflip_z, alphabet_size)\n",
    "    p_value_array_priv_10_n_20000[i,4] = server_bitflip.release_p_value_permutation(n_permutation)\n",
    "    p_value_array_priv_10_n_20000[i,5] = server_bitflip.release_p_value()\n",
    "elapsed = time.time() - t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03, 0.12, 0.14, 0.14, 0.09, 0.1 ])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(p_value_array_priv_10_n_20000<significance_level).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 3, 1,  ..., 0, 3, 1], device='cuda:0')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## privacy level = 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "privacy_level = 2.0\n",
    "\n",
    "LDPclient = client(device, privacy_level)\n",
    "server_elltwo = server_ell2(device, privacy_level)\n",
    "server_genrr = server_multinomial_genRR(device, privacy_level)\n",
    "server_bitflip = server_multinomial_bitflip(device, privacy_level)\n",
    "\n",
    "t = time.time()\n",
    "for i in range(n_test):\n",
    "    print(f\"{i+1}th test\")\n",
    "    torch.manual_seed(i)\n",
    "    data_y = data_gen.generate_multinomial_data(p1, sample_size)\n",
    "    data_z = data_gen.generate_multinomial_data(p2, sample_size)\n",
    "    \n",
    "    LDPclient.load_data_multinomial(data_y, data_z, alphabet_size)\n",
    "    data_list_lapu_y, data_list_lapu_z = LDPclient.release_LapU()\n",
    "    data_list_genrr_y, data_list_genrr_z = LDPclient.release_genRR()\n",
    "    data_list_bitflip_y, data_list_bitflip_z = LDPclient.release_bitFlip()\n",
    "    \n",
    "    server_elltwo.load_private_data_multinomial(data_list_lapu_y, data_list_lapu_z, alphabet_size)\n",
    "    p_value_array_priv_20[i,0] = server_elltwo.release_p_value_permutation(n_permutation)\n",
    " \n",
    "    server_genrr.load_private_data_multinomial(data_list_genrr_y, data_list_genrr_z, alphabet_size)\n",
    "    p_value_array_priv_20[i,1] = server_genrr.release_p_value()\n",
    "     \n",
    "    server_bitflip.load_private_data_multinomial(data_list_bitflip_y, data_list_bitflip_z, alphabet_size)\n",
    "    p_value_array_priv_20[i,2] = server_bitflip.release_p_value()\n",
    "elapsed = time.time() - t\n",
    "print(elapsed)\n",
    "print(\n",
    "   # f\"small chi-square distance\\n\"+\n",
    "        f\"privacy level = {privacy_level}\"\n",
    ")\n",
    "\n",
    "\n",
    "with open('/mnt/nas/users/mjm/LDPUts/simul/type_1/hi_dim/power_law/k_500_n_500_alpha_20_type_1_powerlaw', 'wb') as f:\n",
    "    np.save(f, p_value_array_priv_20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
